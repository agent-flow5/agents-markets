# ==========================================
# OpenAI 配置
# ==========================================
# 你的 OpenAI API Key（仅在服务端使用，请勿暴露到前端）
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ==========================================
# 火山引擎 (Volcengine) / 豆包（方舟平台）配置
# ==========================================
# 火山引擎同样提供兼容 OpenAI 协议的接口，本项目通过 baseURL + apiKey 进行对接
VOLCENGINE_API_KEY=your-volcengine-api-key

# 方舟平台 OpenAI 兼容 API 的固定地址（不要加反引号）
# 常见区域示例：北京
VOLCENGINE_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# ==========================================
# 火山引擎推理接入点 (Endpoint ID) 预设
# ==========================================
# 注意：豆包在方舟平台通常使用 Endpoint ID 作为“模型名”，形如 ep-20240604-xxxx
# 你可以把常用的 Endpoint ID 作为默认值配置在这里，后端也支持请求体动态传入 modelId

# 豆包 Pro 32k（示例）
VOLCENGINE_MODEL_DOUBAO_PRO=ep-20250101000000-xxxxx

# 豆包 Lite 4k（示例）
VOLCENGINE_MODEL_DOUBAO_LITE=ep-20250101000000-yyyyy

# ==========================================
# 后端服务（NestJS）运行配置
# ==========================================
# 后端监听端口（默认 3000）
BACKEND_PORT=3000

# 允许跨域访问的前端地址（Vite dev server 默认 5173）
CORS_ORIGIN=http://localhost:5173

# OpenAI 默认模型（仅当 provider=openai 时用到）
OPENAI_MODEL_ID=gpt-4o-mini
